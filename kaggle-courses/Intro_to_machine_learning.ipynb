{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro-to-machine-learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Notes for **Intro to Machine Learning** Course provided on Kaggle."
      ],
      "metadata": {
        "id": "GwTJ6nJKrfdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Decision Tree: 2 possible predictions\n",
        "- Fitting / Training: The process of capturing patterns from data (training data)\n",
        "- The major shortcoming of Decision Tree is that it doesn't capture most factors affecting the prediction. We could capture more factors using a tree with more \"splits\" (deeper trees).\n",
        "- Leaf: Nodes at the bottom of the tree that do not have any child."
      ],
      "metadata": {
        "id": "uoT278jEsmYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Components in the data:\n",
        " - DataFrame: Holds data in the form of table. Similar to sheet in Excel and table in a SQL database.\n",
        " - Using Pandas library to work with data in this course."
      ],
      "metadata": {
        "id": "zYxG2brhumhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd   # library for manipulating data\n",
        "\n",
        "# file path \n",
        "file_path = \"../file_Directory/file_SubDirectory/file.csv\"\n",
        "\n",
        "# import the data and store it in DataFrame df\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# summary of the data in df\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "c8KDqnZPra-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Components in describe() for numeric columns:\n",
        "- count: Number of rows with non-null values\n",
        "- mean: Average value of that column\n",
        "- std: Standard Deviation (how the values are numerically spread)\n",
        "- min: Smallest value\n",
        "- 25%, 50%, 75%: nth precentile\n",
        "- max: Largest Value"
      ],
      "metadata": {
        "id": "y3LIyArJvy4d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNSkiWE_rYCI"
      },
      "outputs": [],
      "source": [
        "# display all columns in dataframe\n",
        "df.columns\n",
        "\n",
        "# dropping null values\n",
        "df = df.dropna(axis = 0)\n",
        "\n",
        "# 2 ways to access a single attribute/features (columns in dataframe)\n",
        "# return in Series\n",
        "att1 = df.att1    # dot-notation\n",
        "att1 = df[\"att1\"] \n",
        "\n",
        "# providing a list of columns names inside square brackets\n",
        "many_att = df[\"att1\", \"att2\", \"att3\", \"att4\"]   \n",
        "\n",
        "# the first n rows (5 rows by default)\n",
        "df.head()   # first 5 rows\n",
        "df.head(10)   # first 10 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use scikit-learn library to create the machine learning model. Scikit-learn (written as sklearn) is the most popular library for modeling the types of data typically stored in DataFrames\n",
        "- Steps to build model:\n",
        "    1. Define \n",
        "        - Model and their parameters to use\n",
        "    2. Fit\n",
        "       - Capture patterns (train) from training data. \n",
        "    3. Predict\n",
        "    4. Evaluate\n",
        "       - Determine the accuracy of the model'spredictions\n",
        "\n"
      ],
      "metadata": {
        "id": "RTxIAjvd1bXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import scikit-learn library and the model to be used\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# create an object of the model and specify random_state to ensure we'll get the same result each run\n",
        "# the number assigned to random_state will not affect the result of prediction\n",
        "# step 1 of building model\n",
        "df_model = DecisionTreeRegressor (random_state = 1)\n",
        "\n",
        "# step 2: fit the model\n",
        "# X are the predictive features\n",
        "# y is the label feature (the result)\n",
        "df_model.fit(X, y)\n",
        "\n",
        "# step 3: predict\n",
        "df_model.predict(X)"
      ],
      "metadata": {
        "id": "4x666FI31TvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Validation\n",
        " - Mean Absolute Error (MAE)\n",
        "    - error = actual - predicted\n",
        "    - MAE will consider the absolute value of each error and take the average of those absolute errors\n",
        "    - Measure of model quality\n",
        "\n",
        " - Validation data (or Test Data): Data that only used for measuring the model's accuracy. Not invlove in model training nor model prediction. "
      ],
      "metadata": {
        "id": "wvWXQ6_t7os5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the MAE using methods in sklearn\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# the prediction\n",
        "predictions = df_model.predict(X)\n",
        "\n",
        "# MAE\n",
        "mean_absolute_error(y, predictions)"
      ],
      "metadata": {
        "id": "bPl2V0a03i9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# random_state make sure that we get the same split for each run\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
        "\n",
        "df_model = DecisionTreeRegressor()\n",
        "\n",
        "# fit the model using train set\n",
        "df_model.fit(X_train, y_train)\n",
        "\n",
        "# use test set to predict\n",
        "predictions = df_model.predict(X_test)\n",
        "\n",
        "# get the MAE\n",
        "print(mean_absolute_error(y_test, predictions))"
      ],
      "metadata": {
        "id": "YZWKLpp29xmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Underfitting and Overfitting\n",
        " - Overfitting\n",
        "    - A model matches the training data prefectly but does poorly in validation and other new data.\n",
        "    - Usually occur on Decision Tree with higher tree depth\n",
        "    - Lower MAE\n",
        " - Underfitting\n",
        "    - A model fials to capture important distinction and patterns in the data and i preforms poorly in training data.\n",
        "    - Usually occur on Decision Tree with lower tree depth\n",
        "    - Lower MAE\n"
      ],
      "metadata": {
        "id": "sEYMxLLmBwtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to control tree depth?\n",
        "- max_leaf_nodes argument can control overfitting and underfiting.\n",
        "- The more leaves a model has, the more we move from underfitting to overfitting."
      ],
      "metadata": {
        "id": "a62qPe_kD4JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare MAE scores for model with different max_leaf_nodes\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def model_MAE(max_leaf_nodes, X, y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "  df_model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 42)\n",
        "  df_model.fit(X_train, y_train)\n",
        "  return mean_absolute_error(y_test, df_model.predict(X_test))"
      ],
      "metadata": {
        "id": "nVNTpQv5DFCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get MAE for different max_leaf_nodes \n",
        "for n in [5, 50, 500, 5000]:\n",
        "  mae = model_MAE(n, X, y)\n",
        "  print(\"Max leaf nodes: %d \\t\\t Mean Absolute Error: %d\"%(n, mae))"
      ],
      "metadata": {
        "id": "on_ivBTKFmct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Model\n",
        " - Uses many trees and makes a prediction by averaging the predictions of each component tree.\n",
        " - Has better predictive accuracy than a single decision tree.\n",
        " - Works well with default parameters, but many of those are sensitive to getting the right parameters."
      ],
      "metadata": {
        "id": "N6M2W8r0MHiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building random forest model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "forest_model = RandomForestRegressor(random_state = 1)\n",
        "forest_model.fit(X_train, y_train)\n",
        "predictions = forest_model.predict(X_test)\n",
        "print(\"Mean absolute error of using Random Forest Model: {}\".format(mean_absolute_error(y_test, predictions)))"
      ],
      "metadata": {
        "id": "ay_haPgUMIB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}